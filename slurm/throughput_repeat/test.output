WORLD_SIZE=8
MASTER_ADDR=udc-an26-1
Running DP benchmark with args: Namespace(batch_size=1, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 1022.46 | loss 25.91 | ppl 179576817165.70
| batch     2 | wps 2372.25 | loss 12.78 | ppl 355255.30
| batch     3 | wps 2382.24 | loss 12.60 | ppl 297416.58
| batch     4 | wps 2382.20 | loss 12.49 | ppl 266776.97
| batch     5 | wps 2385.75 | loss 12.44 | ppl 251479.50
| batch     6 | wps 2376.56 | loss 12.24 | ppl 207549.66
| batch     7 | wps 2384.17 | loss 12.22 | ppl 203083.52
| batch     8 | wps 2382.67 | loss 12.31 | ppl 222113.88
| batch     9 | wps 2382.03 | loss 11.94 | ppl 152877.94
| batch    10 | wps 2386.68 | loss 11.94 | ppl 154027.91
| batch    11 | wps 2384.32 | loss 11.84 | ppl 138736.41
| batch    12 | wps 2382.11 | loss 11.83 | ppl 137704.81
| batch    13 | wps 2385.11 | loss 11.78 | ppl 130029.48
| batch    14 | wps 2385.51 | loss 11.72 | ppl 123594.11
| batch    15 | wps 2380.02 | loss 11.67 | ppl 117244.87
| batch    16 | wps 2382.59 | loss 11.47 | ppl 95908.91
| batch    17 | wps 2384.43 | loss 11.46 | ppl 95233.00
| batch    18 | wps 2382.07 | loss 11.36 | ppl 85646.66
| batch    19 | wps 2386.38 | loss 11.44 | ppl 92639.07
| batch    20 | wps 2385.56 | loss 11.27 | ppl 78191.88
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 10.65s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2345.66.
Elapsed_time(s) is 10.65.
Peak allocated bytes on cuda:0: 19.236468GB
Running DP benchmark with args: Namespace(batch_size=2, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 1556.35 | loss 25.81 | ppl 161706938718.90
| batch     2 | wps 2662.35 | loss 12.60 | ppl 296384.23
| batch     3 | wps 2663.59 | loss 12.35 | ppl 232016.04
| batch     4 | wps 2665.36 | loss 12.21 | ppl 201165.37
| batch     5 | wps 2665.90 | loss 12.07 | ppl 173951.89
| batch     6 | wps 2667.33 | loss 12.02 | ppl 166223.98
| batch     7 | wps 2670.15 | loss 11.97 | ppl 158390.89
| batch     8 | wps 2665.25 | loss 11.77 | ppl 129225.69
| batch     9 | wps 2669.39 | loss 11.79 | ppl 131357.38
| batch    10 | wps 2663.57 | loss 11.63 | ppl 112237.26
| batch    11 | wps 2667.32 | loss 11.51 | ppl 99801.23
| batch    12 | wps 2663.02 | loss 11.53 | ppl 102229.74
| batch    13 | wps 2343.91 | loss 11.36 | ppl 85978.18
| batch    14 | wps 2665.51 | loss 11.33 | ppl 83047.54
| batch    15 | wps 2666.39 | loss 11.22 | ppl 74577.70
| batch    16 | wps 2665.80 | loss 11.14 | ppl 68995.93
| batch    17 | wps 2664.98 | loss 11.05 | ppl 62978.85
| batch    18 | wps 2664.94 | loss 11.04 | ppl 62228.86
| batch    19 | wps 2664.10 | loss 10.97 | ppl 58143.74
| batch    20 | wps 2665.56 | loss 10.92 | ppl 55485.65
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 17.68s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2641.53.
Elapsed_time(s) is 17.68.
Peak allocated bytes on cuda:0: 19.375125GB
Running DP benchmark with args: Namespace(batch_size=3, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 1926.94 | loss 25.82 | ppl 163860120401.15
| batch     2 | wps 2786.75 | loss 12.55 | ppl 282509.89
| batch     3 | wps 2777.33 | loss 12.27 | ppl 212150.23
| batch     4 | wps 2786.29 | loss 12.15 | ppl 188380.16
| batch     5 | wps 2784.84 | loss 12.04 | ppl 168700.80
| batch     6 | wps 2786.31 | loss 11.95 | ppl 154637.09
| batch     7 | wps 2784.47 | loss 11.76 | ppl 127618.14
| batch     8 | wps 2540.91 | loss 11.74 | ppl 125937.11
| batch     9 | wps 2787.60 | loss 11.61 | ppl 110321.76
| batch    10 | wps 2786.87 | loss 11.49 | ppl 97804.47
| batch    11 | wps 2787.76 | loss 11.40 | ppl 89477.46
| batch    12 | wps 2789.20 | loss 11.41 | ppl 90041.57
| batch    13 | wps 2786.57 | loss 11.27 | ppl 78166.97
| batch    14 | wps 2787.35 | loss 11.18 | ppl 71832.32
| batch    15 | wps 2787.08 | loss 11.12 | ppl 67543.38
| batch    16 | wps 2786.18 | loss 11.00 | ppl 59940.64
| batch    17 | wps 2787.34 | loss 10.93 | ppl 55996.12
| batch    18 | wps 2785.65 | loss 10.82 | ppl 49981.32
| batch    19 | wps 2786.82 | loss 10.78 | ppl 48051.35
| batch    20 | wps 2787.21 | loss 10.74 | ppl 45956.90
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 24.57s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2766.50.
Elapsed_time(s) is 24.57.
Peak allocated bytes on cuda:0: 21.871565GB
Running DP benchmark with args: Namespace(batch_size=4, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 2142.78 | loss 25.75 | ppl 152775507957.90
| batch     2 | wps 2881.77 | loss 12.51 | ppl 270163.22
| batch     3 | wps 2880.58 | loss 12.27 | ppl 212177.34
| batch     4 | wps 2880.49 | loss 12.12 | ppl 183201.76
| batch     5 | wps 2881.14 | loss 11.91 | ppl 149146.66
| batch     6 | wps 2678.20 | loss 11.86 | ppl 141500.13
| batch     7 | wps 2880.35 | loss 11.73 | ppl 124548.98
| batch     8 | wps 2879.78 | loss 11.61 | ppl 109772.77
| batch     9 | wps 2878.80 | loss 11.55 | ppl 104063.97
| batch    10 | wps 2880.35 | loss 11.44 | ppl 93395.74
| batch    11 | wps 2878.88 | loss 11.36 | ppl 85971.95
| batch    12 | wps 2878.38 | loss 11.23 | ppl 75260.10
| batch    13 | wps 2877.55 | loss 11.12 | ppl 67412.55
| batch    14 | wps 2876.95 | loss 11.08 | ppl 64735.74
| batch    15 | wps 2877.34 | loss 11.01 | ppl 60247.60
| batch    16 | wps 2875.55 | loss 10.94 | ppl 56361.14
| batch    17 | wps 2875.00 | loss 10.82 | ppl 50038.41
| batch    18 | wps 2874.37 | loss 10.77 | ppl 47436.85
| batch    19 | wps 2872.90 | loss 10.70 | ppl 44145.81
| batch    20 | wps 2875.34 | loss 10.66 | ppl 42681.83
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 31.31s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2862.16.
Elapsed_time(s) is 31.31.
Peak allocated bytes on cuda:0: 24.870005GB
Running DP benchmark with args: Namespace(batch_size=5, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 2311.61 | loss 25.71 | ppl 145758277658.05
| batch     2 | wps 2910.80 | loss 12.45 | ppl 254588.77
| batch     3 | wps 2909.89 | loss 12.24 | ppl 206745.23
| batch     4 | wps 2906.92 | loss 12.02 | ppl 166734.74
| batch     5 | wps 2742.09 | loss 11.92 | ppl 150313.99
| batch     6 | wps 2907.23 | loss 11.76 | ppl 127550.37
| batch     7 | wps 2905.08 | loss 11.71 | ppl 121399.08
| batch     8 | wps 2906.54 | loss 11.58 | ppl 107171.31
| batch     9 | wps 2903.30 | loss 11.46 | ppl 94399.12
| batch    10 | wps 2905.12 | loss 11.36 | ppl 85715.38
| batch    11 | wps 2903.97 | loss 11.26 | ppl 77733.73
| batch    12 | wps 2902.52 | loss 11.20 | ppl 73263.83
| batch    13 | wps 2902.60 | loss 11.10 | ppl 66413.51
| batch    14 | wps 2901.69 | loss 11.00 | ppl 60039.16
| batch    15 | wps 2901.67 | loss 10.95 | ppl 56831.52
| batch    16 | wps 2901.20 | loss 10.87 | ppl 52458.66
| batch    17 | wps 2898.77 | loss 10.75 | ppl 46533.67
| batch    18 | wps 2897.11 | loss 10.68 | ppl 43584.21
| batch    19 | wps 2900.54 | loss 10.57 | ppl 39057.83
| batch    20 | wps 2900.25 | loss 10.51 | ppl 36678.98
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 38.39s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2891.70.
Elapsed_time(s) is 38.39.
Peak allocated bytes on cuda:0: 27.972295GB
Running DP benchmark with args: Namespace(batch_size=6, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 2460.68 | loss 25.71 | ppl 145904028691.65
| batch     2 | wps 2958.61 | loss 12.43 | ppl 250439.36
| batch     3 | wps 2958.68 | loss 12.20 | ppl 199040.28
| batch     4 | wps 2812.62 | loss 12.05 | ppl 170964.22
| batch     5 | wps 2952.87 | loss 11.88 | ppl 144238.97
| batch     6 | wps 2954.61 | loss 11.78 | ppl 130633.55
| batch     7 | wps 2954.05 | loss 11.66 | ppl 115494.99
| batch     8 | wps 2948.30 | loss 11.51 | ppl 99537.08
| batch     9 | wps 2945.91 | loss 11.40 | ppl 88937.57
| batch    10 | wps 2947.99 | loss 11.33 | ppl 83512.79
| batch    11 | wps 2949.71 | loss 11.24 | ppl 76135.48
| batch    12 | wps 2945.53 | loss 11.16 | ppl 70523.69
| batch    13 | wps 2946.50 | loss 11.08 | ppl 64677.67
| batch    14 | wps 2948.34 | loss 10.95 | ppl 56716.09
| batch    15 | wps 2947.50 | loss 10.87 | ppl 52660.11
| batch    16 | wps 2950.23 | loss 10.74 | ppl 45976.28
| batch    17 | wps 2951.01 | loss 10.73 | ppl 45842.17
| batch    18 | wps 2948.84 | loss 10.63 | ppl 41169.74
| batch    19 | wps 2945.59 | loss 10.56 | ppl 38500.04
| batch    20 | wps 2800.75 | loss 10.47 | ppl 35221.83
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 45.13s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2933.78.
Elapsed_time(s) is 45.13.
Peak allocated bytes on cuda:0: 30.956813GB
Running DP benchmark with args: Namespace(batch_size=7, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 2516.52 | loss 25.71 | ppl 146426477025.83
| batch     2 | wps 2967.97 | loss 12.49 | ppl 265868.72
| batch     3 | wps 2839.99 | loss 12.19 | ppl 196141.22
| batch     4 | wps 2962.04 | loss 12.02 | ppl 165550.36
| batch     5 | wps 2964.04 | loss 11.90 | ppl 146747.14
| batch     6 | wps 2962.11 | loss 11.75 | ppl 127035.53
| batch     7 | wps 2961.21 | loss 11.59 | ppl 108329.70
| batch     8 | wps 2960.59 | loss 11.51 | ppl 99439.45
| batch     9 | wps 2961.13 | loss 11.41 | ppl 90558.35
| batch    10 | wps 2955.39 | loss 11.30 | ppl 81115.39
| batch    11 | wps 2957.06 | loss 11.24 | ppl 75854.42
| batch    12 | wps 2953.82 | loss 11.10 | ppl 66401.04
| batch    13 | wps 2953.75 | loss 11.00 | ppl 59667.00
| batch    14 | wps 2952.58 | loss 10.90 | ppl 54069.34
| batch    15 | wps 2954.35 | loss 10.85 | ppl 51485.59
| batch    16 | wps 2953.16 | loss 10.77 | ppl 47464.55
| batch    17 | wps 2955.42 | loss 10.66 | ppl 42597.21
| batch    18 | wps 2953.00 | loss 10.60 | ppl 40178.86
| batch    19 | wps 2954.83 | loss 10.51 | ppl 36640.11
| batch    20 | wps 2830.84 | loss 10.46 | ppl 34917.18
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 52.30s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2943.94.
Elapsed_time(s) is 52.30.
Peak allocated bytes on cuda:0: 34.030482GB
Running DP benchmark with args: Namespace(batch_size=8, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 2590.03 | loss 25.69 | ppl 144152770526.20
| batch     2 | wps 2995.53 | loss 12.47 | ppl 261143.67
| batch     3 | wps 2882.05 | loss 12.21 | ppl 200248.71
| batch     4 | wps 2992.43 | loss 12.03 | ppl 167238.61
| batch     5 | wps 2994.21 | loss 11.90 | ppl 146951.75
| batch     6 | wps 2991.58 | loss 11.70 | ppl 121149.50
| batch     7 | wps 2992.60 | loss 11.62 | ppl 111411.94
| batch     8 | wps 2992.61 | loss 11.50 | ppl 98553.70
| batch     9 | wps 2991.36 | loss 11.40 | ppl 89280.21
| batch    10 | wps 2990.73 | loss 11.29 | ppl 80119.84
| batch    11 | wps 2988.12 | loss 11.19 | ppl 72312.56
| batch    12 | wps 2989.82 | loss 11.06 | ppl 63814.27
| batch    13 | wps 2985.76 | loss 11.00 | ppl 60158.89
| batch    14 | wps 2872.57 | loss 10.91 | ppl 54648.92
| batch    15 | wps 2987.91 | loss 10.81 | ppl 49633.10
| batch    16 | wps 2988.79 | loss 10.73 | ppl 45731.44
| batch    17 | wps 2987.52 | loss 10.66 | ppl 42794.57
| batch    18 | wps 2984.88 | loss 10.55 | ppl 38329.24
| batch    19 | wps 2984.61 | loss 10.48 | ppl 35686.91
| batch    20 | wps 2986.74 | loss 10.43 | ppl 33982.94
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 58.96s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2976.52.
Elapsed_time(s) is 58.96.
Peak allocated bytes on cuda:0: 37.080183GB
Running DP benchmark with args: Namespace(batch_size=9, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 2657.43 | loss 25.68 | ppl 141761382961.11
| batch     2 | wps 3025.31 | loss 12.52 | ppl 273541.06
| batch     3 | wps 2918.40 | loss 12.19 | ppl 196183.50
| batch     4 | wps 3020.40 | loss 12.05 | ppl 171083.78
| batch     5 | wps 3021.04 | loss 11.85 | ppl 140783.37
| batch     6 | wps 3020.64 | loss 11.72 | ppl 122862.32
| batch     7 | wps 3016.97 | loss 11.60 | ppl 108923.81
| batch     8 | wps 3014.21 | loss 11.50 | ppl 98400.90
| batch     9 | wps 3017.04 | loss 11.38 | ppl 87162.98
| batch    10 | wps 3009.60 | loss 11.26 | ppl 77902.86
| batch    11 | wps 3015.41 | loss 11.16 | ppl 70298.87
| batch    12 | wps 2913.83 | loss 11.09 | ppl 65639.83
| batch    13 | wps 3012.41 | loss 10.96 | ppl 57681.97
| batch    14 | wps 3013.78 | loss 10.88 | ppl 53252.40
| batch    15 | wps 3014.04 | loss 10.81 | ppl 49756.13
| batch    16 | wps 3012.14 | loss 10.71 | ppl 44628.81
| batch    17 | wps 3013.02 | loss 10.62 | ppl 40883.76
| batch    18 | wps 3013.05 | loss 10.52 | ppl 37123.10
| batch    19 | wps 3014.82 | loss 10.47 | ppl 35369.37
| batch    20 | wps 3015.06 | loss 10.41 | ppl 33226.95
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 65.56s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3004.38.
Elapsed_time(s) is 65.56.
Peak allocated bytes on cuda:0: 40.151668GB
Running DP benchmark with args: Namespace(batch_size=10, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 2703.60 | loss 25.68 | ppl 141863761913.77
| batch     2 | wps 2952.86 | loss 12.44 | ppl 253948.60
| batch     3 | wps 3049.72 | loss 12.20 | ppl 198966.83
| batch     4 | wps 3048.63 | loss 12.01 | ppl 164334.74
| batch     5 | wps 3046.20 | loss 11.84 | ppl 138452.37
| batch     6 | wps 3048.02 | loss 11.71 | ppl 121500.66
| batch     7 | wps 3046.22 | loss 11.58 | ppl 107107.14
| batch     8 | wps 3046.97 | loss 11.46 | ppl 95035.67
| batch     9 | wps 3045.20 | loss 11.34 | ppl 83708.55
| batch    10 | wps 3042.23 | loss 11.24 | ppl 75885.39
| batch    11 | wps 2951.53 | loss 11.15 | ppl 69824.88
| batch    12 | wps 3045.94 | loss 11.03 | ppl 61482.59
| batch    13 | wps 3039.06 | loss 10.96 | ppl 57456.81
| batch    14 | wps 3039.72 | loss 10.86 | ppl 52176.66
| batch    15 | wps 3037.72 | loss 10.75 | ppl 46574.87
| batch    16 | wps 3037.49 | loss 10.67 | ppl 42841.81
| batch    17 | wps 3039.38 | loss 10.60 | ppl 39961.46
| batch    18 | wps 3039.77 | loss 10.53 | ppl 37240.89
| batch    19 | wps 3039.62 | loss 10.46 | ppl 34852.74
| batch    20 | wps 2943.50 | loss 10.37 | ppl 31741.62
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 72.20s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3027.63.
Elapsed_time(s) is 72.20.
Peak allocated bytes on cuda:0: 43.207438GB
Running DP benchmark with args: Namespace(batch_size=11, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 2715.06 | loss 25.65 | ppl 137576460891.74
| batch     2 | wps 2959.99 | loss 12.47 | ppl 260424.42
| batch     3 | wps 3044.77 | loss 12.23 | ppl 205349.48
| batch     4 | wps 3041.86 | loss 12.01 | ppl 164264.23
| batch     5 | wps 3042.92 | loss 11.85 | ppl 140467.54
| batch     6 | wps 3041.46 | loss 11.71 | ppl 121475.52
| batch     7 | wps 3041.95 | loss 11.59 | ppl 107701.74
| batch     8 | wps 3037.88 | loss 11.45 | ppl 94036.02
| batch     9 | wps 3037.04 | loss 11.33 | ppl 83347.06
| batch    10 | wps 2952.91 | loss 11.24 | ppl 76454.97
| batch    11 | wps 3035.73 | loss 11.14 | ppl 68750.80
| batch    12 | wps 3038.18 | loss 11.04 | ppl 62016.53
| batch    13 | wps 3035.08 | loss 10.95 | ppl 56867.96
| batch    14 | wps 3035.41 | loss 10.84 | ppl 50843.37
| batch    15 | wps 3035.81 | loss 10.73 | ppl 45848.47
| batch    16 | wps 3034.69 | loss 10.68 | ppl 43516.02
| batch    17 | wps 3034.43 | loss 10.61 | ppl 40579.42
| batch    18 | wps 2951.23 | loss 10.50 | ppl 36293.31
| batch    19 | wps 3034.37 | loss 10.42 | ppl 33467.44
| batch    20 | wps 3038.34 | loss 10.35 | ppl 31175.78
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 79.42s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3024.15.
Elapsed_time(s) is 79.42.
Peak allocated bytes on cuda:0: 46.288806GB
Running DP benchmark with args: Namespace(batch_size=12, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 2771.29 | loss 25.65 | ppl 137309852374.16
| batch     2 | wps 2986.92 | loss 12.44 | ppl 252621.52
| batch     3 | wps 3065.65 | loss 12.20 | ppl 199716.42
| batch     4 | wps 3063.57 | loss 11.97 | ppl 158370.80
| batch     5 | wps 3063.18 | loss 11.83 | ppl 136708.52
| batch     6 | wps 3067.83 | loss 11.70 | ppl 121021.55
| batch     7 | wps 3064.80 | loss 11.54 | ppl 103100.74
| batch     8 | wps 3064.38 | loss 11.42 | ppl 91379.04
| batch     9 | wps 2985.78 | loss 11.33 | ppl 83679.41
| batch    10 | wps 3066.82 | loss 11.22 | ppl 74524.03
| batch    11 | wps 3069.52 | loss 11.13 | ppl 67855.54
| batch    12 | wps 3069.26 | loss 11.01 | ppl 60723.60
| batch    13 | wps 3068.36 | loss 10.91 | ppl 54942.81
| batch    14 | wps 3064.04 | loss 10.80 | ppl 49253.38
| batch    15 | wps 3069.18 | loss 10.76 | ppl 46869.13
| batch    16 | wps 3063.80 | loss 10.66 | ppl 42567.24
| batch    17 | wps 2986.75 | loss 10.55 | ppl 38082.79
| batch    18 | wps 3064.34 | loss 10.47 | ppl 35354.43
| batch    19 | wps 3065.15 | loss 10.41 | ppl 33183.66
| batch    20 | wps 3061.89 | loss 10.34 | ppl 31035.44
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 85.73s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3052.40.
Elapsed_time(s) is 85.73.
Peak allocated bytes on cuda:0: 49.337985GB
Running DP benchmark with args: Namespace(batch_size=13, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 2790.84 | loss 25.67 | ppl 140511378194.26
| batch     2 | wps 3000.12 | loss 12.43 | ppl 249488.45
| batch     3 | wps 3070.65 | loss 12.17 | ppl 192529.19
| batch     4 | wps 3072.89 | loss 11.95 | ppl 154505.16
| batch     5 | wps 3071.84 | loss 11.80 | ppl 133030.17
| batch     6 | wps 3066.58 | loss 11.67 | ppl 116661.10
| batch     7 | wps 3067.91 | loss 11.51 | ppl 99906.84
| batch     8 | wps 2988.24 | loss 11.43 | ppl 91926.21
| batch     9 | wps 3062.27 | loss 11.29 | ppl 79681.93
| batch    10 | wps 3061.38 | loss 11.22 | ppl 74329.90
| batch    11 | wps 3062.52 | loss 11.10 | ppl 66392.36
| batch    12 | wps 3064.39 | loss 10.97 | ppl 58298.77
| batch    13 | wps 3060.84 | loss 10.88 | ppl 53248.19
| batch    14 | wps 3061.12 | loss 10.81 | ppl 49396.38
| batch    15 | wps 2987.58 | loss 10.72 | ppl 45065.82
| batch    16 | wps 3062.03 | loss 10.61 | ppl 40636.93
| batch    17 | wps 3062.27 | loss 10.52 | ppl 37177.66
| batch    18 | wps 3062.97 | loss 10.47 | ppl 35337.37
| batch    19 | wps 3061.87 | loss 10.38 | ppl 32266.24
| batch    20 | wps 3063.58 | loss 10.31 | ppl 30076.96
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 92.76s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3052.80.
Elapsed_time(s) is 92.76.
Peak allocated bytes on cuda:0: 52.426176GB
Running DP benchmark with args: Namespace(batch_size=14, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 2828.36 | loss 25.67 | ppl 141265279223.92
| batch     2 | wps 3025.73 | loss 12.44 | ppl 251832.06
| batch     3 | wps 3095.51 | loss 12.15 | ppl 189848.59
| batch     4 | wps 3092.58 | loss 11.96 | ppl 156675.22
| batch     5 | wps 3093.65 | loss 11.81 | ppl 135148.04
| batch     6 | wps 3090.57 | loss 11.65 | ppl 114374.67
| batch     7 | wps 3089.59 | loss 11.52 | ppl 100839.56
| batch     8 | wps 3022.56 | loss 11.42 | ppl 90965.26
| batch     9 | wps 3086.66 | loss 11.30 | ppl 80746.15
| batch    10 | wps 3093.49 | loss 11.21 | ppl 73657.20
| batch    11 | wps 3091.30 | loss 11.08 | ppl 64952.99
| batch    12 | wps 3087.43 | loss 10.96 | ppl 57699.24
| batch    13 | wps 3088.19 | loss 10.89 | ppl 53829.02
| batch    14 | wps 3020.85 | loss 10.80 | ppl 48939.02
| batch    15 | wps 3090.33 | loss 10.69 | ppl 43899.62
| batch    16 | wps 3085.53 | loss 10.61 | ppl 40411.31
| batch    17 | wps 3088.55 | loss 10.54 | ppl 37717.12
| batch    18 | wps 3087.85 | loss 10.45 | ppl 34693.99
| batch    19 | wps 3084.31 | loss 10.37 | ppl 31850.00
| batch    20 | wps 3086.64 | loss 10.31 | ppl 29881.95
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 99.06s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3075.37.
Elapsed_time(s) is 99.06.
Peak allocated bytes on cuda:0: 55.454464GB
Running FSDP benchmark with args: Namespace(batch_size=1, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 132.18 | loss 25.91 | ppl 179576817165.70
| batch     2 | wps 2355.52 | loss 12.78 | ppl 355261.06
| batch     3 | wps 2556.14 | loss 12.60 | ppl 297421.69
| batch     4 | wps 2550.99 | loss 12.49 | ppl 266768.58
| batch     5 | wps 2556.57 | loss 12.44 | ppl 251497.97
| batch     6 | wps 2555.56 | loss 12.24 | ppl 207535.41
| batch     7 | wps 2553.82 | loss 12.22 | ppl 203081.00
| batch     8 | wps 2555.83 | loss 12.31 | ppl 222106.26
| batch     9 | wps 2554.20 | loss 11.94 | ppl 152858.84
| batch    10 | wps 2550.78 | loss 11.94 | ppl 154022.47
| batch    11 | wps 2556.21 | loss 11.84 | ppl 138750.57
| batch    12 | wps 2553.81 | loss 11.83 | ppl 137751.31
| batch    13 | wps 2553.83 | loss 11.78 | ppl 130048.71
| batch    14 | wps 2553.49 | loss 11.72 | ppl 123566.29
| batch    15 | wps 2557.21 | loss 11.67 | ppl 117178.92
| batch    16 | wps 2550.87 | loss 11.47 | ppl 95877.18
| batch    17 | wps 2556.25 | loss 11.46 | ppl 95263.06
| batch    18 | wps 2555.59 | loss 11.36 | ppl 85632.61
| batch    19 | wps 2550.71 | loss 11.44 | ppl 92605.68
| batch    20 | wps 2554.66 | loss 11.27 | ppl 78217.61
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 23.19s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2531.94.
Elapsed_time(s) is 23.19.
Peak allocated bytes on cuda:0: 10.825978GB
Running FSDP benchmark with args: Namespace(batch_size=2, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 251.43 | loss 25.81 | ppl 161706784503.22
| batch     2 | wps 2830.25 | loss 12.60 | ppl 296378.29
| batch     3 | wps 2830.51 | loss 12.35 | ppl 232016.93
| batch     4 | wps 2829.34 | loss 12.21 | ppl 201124.51
| batch     5 | wps 2828.17 | loss 12.07 | ppl 173924.69
| batch     6 | wps 2831.70 | loss 12.02 | ppl 166146.17
| batch     7 | wps 2821.24 | loss 11.97 | ppl 158385.75
| batch     8 | wps 2830.88 | loss 11.77 | ppl 129186.39
| batch     9 | wps 2829.24 | loss 11.79 | ppl 131348.23
| batch    10 | wps 2832.25 | loss 11.63 | ppl 112221.10
| batch    11 | wps 2826.48 | loss 11.51 | ppl 99783.05
| batch    12 | wps 2456.04 | loss 11.53 | ppl 102215.60
| batch    13 | wps 2830.41 | loss 11.36 | ppl 85991.30
| batch    14 | wps 2832.10 | loss 11.33 | ppl 83044.77
| batch    15 | wps 2828.93 | loss 11.22 | ppl 74590.44
| batch    16 | wps 2827.91 | loss 11.14 | ppl 69004.62
| batch    17 | wps 2829.39 | loss 11.05 | ppl 62996.33
| batch    18 | wps 2828.07 | loss 11.04 | ppl 62224.12
| batch    19 | wps 2812.46 | loss 10.97 | ppl 58137.87
| batch    20 | wps 2829.05 | loss 10.92 | ppl 55511.16
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 30.20s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2800.44.
Elapsed_time(s) is 30.20.
Peak allocated bytes on cuda:0: 11.020527GB
Running FSDP benchmark with args: Namespace(batch_size=3, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 372.01 | loss 25.82 | ppl 163860120401.15
| batch     2 | wps 2895.30 | loss 12.55 | ppl 282507.47
| batch     3 | wps 2886.44 | loss 12.27 | ppl 212145.98
| batch     4 | wps 2893.17 | loss 12.15 | ppl 188395.43
| batch     5 | wps 2893.87 | loss 12.04 | ppl 168716.24
| batch     6 | wps 2620.28 | loss 11.95 | ppl 154648.30
| batch     7 | wps 2893.89 | loss 11.76 | ppl 127595.62
| batch     8 | wps 2892.36 | loss 11.74 | ppl 125953.80
| batch     9 | wps 2892.67 | loss 11.61 | ppl 110345.43
| batch    10 | wps 2893.22 | loss 11.49 | ppl 97810.90
| batch    11 | wps 2894.64 | loss 11.40 | ppl 89490.09
| batch    12 | wps 2893.06 | loss 11.41 | ppl 90072.23
| batch    13 | wps 2894.56 | loss 11.27 | ppl 78186.81
| batch    14 | wps 2894.60 | loss 11.18 | ppl 71834.51
| batch    15 | wps 2894.68 | loss 11.12 | ppl 67555.17
| batch    16 | wps 2893.27 | loss 11.00 | ppl 59956.37
| batch    17 | wps 2894.28 | loss 10.93 | ppl 55995.27
| batch    18 | wps 2893.29 | loss 10.82 | ppl 49981.18
| batch    19 | wps 2895.33 | loss 10.78 | ppl 48069.13
| batch    20 | wps 2893.13 | loss 10.74 | ppl 45969.35
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 36.84s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2873.79.
Elapsed_time(s) is 36.84.
Peak allocated bytes on cuda:0: 13.530239GB
Running FSDP benchmark with args: Namespace(batch_size=4, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 465.18 | loss 25.75 | ppl 152775507957.90
| batch     2 | wps 2962.06 | loss 12.51 | ppl 270161.16
| batch     3 | wps 2963.80 | loss 12.27 | ppl 212175.32
| batch     4 | wps 2962.63 | loss 12.12 | ppl 183198.97
| batch     5 | wps 2747.61 | loss 11.91 | ppl 149145.10
| batch     6 | wps 2963.71 | loss 11.86 | ppl 141501.08
| batch     7 | wps 2956.36 | loss 11.73 | ppl 124543.99
| batch     8 | wps 2961.77 | loss 11.61 | ppl 109775.39
| batch     9 | wps 2964.17 | loss 11.55 | ppl 104081.14
| batch    10 | wps 2963.44 | loss 11.44 | ppl 93401.71
| batch    11 | wps 2961.67 | loss 11.36 | ppl 85968.18
| batch    12 | wps 2961.01 | loss 11.23 | ppl 75254.07
| batch    13 | wps 2956.68 | loss 11.12 | ppl 67407.73
| batch    14 | wps 2961.85 | loss 11.08 | ppl 64737.84
| batch    15 | wps 2960.72 | loss 11.01 | ppl 60258.23
| batch    16 | wps 2961.65 | loss 10.94 | ppl 56366.57
| batch    17 | wps 2958.54 | loss 10.82 | ppl 50041.22
| batch    18 | wps 2960.19 | loss 10.77 | ppl 47442.19
| batch    19 | wps 2957.75 | loss 10.70 | ppl 44141.18
| batch    20 | wps 2955.87 | loss 10.66 | ppl 42674.79
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 44.05s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2945.81.
Elapsed_time(s) is 44.05.
Peak allocated bytes on cuda:0: 16.578655GB
Running FSDP benchmark with args: Namespace(batch_size=5, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 553.03 | loss 25.71 | ppl 145758277658.05
| batch     2 | wps 2979.24 | loss 12.45 | ppl 254590.71
| batch     3 | wps 2800.54 | loss 12.24 | ppl 206744.64
| batch     4 | wps 2985.05 | loss 12.02 | ppl 166734.26
| batch     5 | wps 2981.14 | loss 11.92 | ppl 150312.70
| batch     6 | wps 2979.46 | loss 11.76 | ppl 127549.64
| batch     7 | wps 2982.11 | loss 11.71 | ppl 121395.73
| batch     8 | wps 2975.92 | loss 11.58 | ppl 107168.34
| batch     9 | wps 2979.03 | loss 11.46 | ppl 94398.21
| batch    10 | wps 2974.89 | loss 11.36 | ppl 85714.56
| batch    11 | wps 2974.25 | loss 11.26 | ppl 77731.43
| batch    12 | wps 2974.51 | loss 11.20 | ppl 73261.59
| batch    13 | wps 2974.29 | loss 11.10 | ppl 66413.20
| batch    14 | wps 2973.69 | loss 11.00 | ppl 60036.87
| batch    15 | wps 2972.82 | loss 10.95 | ppl 56830.33
| batch    16 | wps 2969.34 | loss 10.87 | ppl 52457.41
| batch    17 | wps 2968.84 | loss 10.75 | ppl 46531.54
| batch    18 | wps 2966.39 | loss 10.68 | ppl 43584.59
| batch    19 | wps 2966.69 | loss 10.57 | ppl 39059.06
| batch    20 | wps 2965.28 | loss 10.51 | ppl 36678.28
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 51.38s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2962.96.
Elapsed_time(s) is 51.38.
Peak allocated bytes on cuda:0: 19.746578GB
Running FSDP benchmark with args: Namespace(batch_size=6, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 624.44 | loss 25.71 | ppl 145904167836.64
| batch     2 | wps 3014.98 | loss 12.43 | ppl 250437.93
| batch     3 | wps 2859.15 | loss 12.20 | ppl 199053.18
| batch     4 | wps 3013.89 | loss 12.05 | ppl 170970.09
| batch     5 | wps 3013.11 | loss 11.88 | ppl 144247.36
| batch     6 | wps 3007.54 | loss 11.78 | ppl 130629.19
| batch     7 | wps 3007.09 | loss 11.66 | ppl 115487.39
| batch     8 | wps 3007.38 | loss 11.51 | ppl 99533.38
| batch     9 | wps 3005.50 | loss 11.40 | ppl 88946.90
| batch    10 | wps 3007.68 | loss 11.33 | ppl 83501.40
| batch    11 | wps 3006.48 | loss 11.24 | ppl 76122.12
| batch    12 | wps 3001.77 | loss 11.16 | ppl 70524.43
| batch    13 | wps 3002.89 | loss 11.08 | ppl 64675.21
| batch    14 | wps 3005.05 | loss 10.95 | ppl 56719.06
| batch    15 | wps 3003.10 | loss 10.87 | ppl 52656.64
| batch    16 | wps 3004.18 | loss 10.74 | ppl 45973.69
| batch    17 | wps 3005.25 | loss 10.73 | ppl 45841.12
| batch    18 | wps 3002.88 | loss 10.63 | ppl 41172.33
| batch    19 | wps 3003.89 | loss 10.56 | ppl 38502.86
| batch    20 | wps 3004.33 | loss 10.47 | ppl 35220.79
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 58.67s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2996.53.
Elapsed_time(s) is 58.67.
Peak allocated bytes on cuda:0: 22.700390GB
Running FSDP benchmark with args: Namespace(batch_size=7, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 681.87 | loss 25.71 | ppl 146426477025.83
| batch     2 | wps 2884.44 | loss 12.49 | ppl 265869.99
| batch     3 | wps 3021.53 | loss 12.19 | ppl 196138.79
| batch     4 | wps 3021.21 | loss 12.02 | ppl 165549.73
| batch     5 | wps 3015.44 | loss 11.90 | ppl 146750.08
| batch     6 | wps 3015.92 | loss 11.75 | ppl 127033.71
| batch     7 | wps 3009.47 | loss 11.59 | ppl 108332.28
| batch     8 | wps 3016.25 | loss 11.51 | ppl 99444.00
| batch     9 | wps 3015.24 | loss 11.41 | ppl 90565.35
| batch    10 | wps 3010.69 | loss 11.30 | ppl 81116.39
| batch    11 | wps 3010.49 | loss 11.24 | ppl 75858.76
| batch    12 | wps 3014.56 | loss 11.10 | ppl 66411.93
| batch    13 | wps 3016.57 | loss 11.00 | ppl 59673.31
| batch    14 | wps 3012.26 | loss 10.90 | ppl 54070.99
| batch    15 | wps 3010.75 | loss 10.85 | ppl 51484.16
| batch    16 | wps 2881.82 | loss 10.77 | ppl 47464.59
| batch    17 | wps 3012.25 | loss 10.66 | ppl 42596.72
| batch    18 | wps 3011.64 | loss 10.60 | ppl 40179.01
| batch    19 | wps 3009.73 | loss 10.51 | ppl 36641.57
| batch    20 | wps 3008.70 | loss 10.46 | ppl 34919.75
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 66.49s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2998.28.
Elapsed_time(s) is 66.49.
Peak allocated bytes on cuda:0: 25.818508GB
Running FSDP benchmark with args: Namespace(batch_size=8, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 815.43 | loss 25.69 | ppl 144152770526.20
| batch     2 | wps 2928.60 | loss 12.47 | ppl 261143.67
| batch     3 | wps 3048.92 | loss 12.21 | ppl 200242.41
| batch     4 | wps 3045.64 | loss 12.03 | ppl 167231.27
| batch     5 | wps 3046.14 | loss 11.90 | ppl 146951.61
| batch     6 | wps 3044.69 | loss 11.70 | ppl 121148.80
| batch     7 | wps 3042.57 | loss 11.62 | ppl 111412.69
| batch     8 | wps 3040.74 | loss 11.50 | ppl 98554.54
| batch     9 | wps 3041.46 | loss 11.40 | ppl 89279.53
| batch    10 | wps 3038.75 | loss 11.29 | ppl 80117.09
| batch    11 | wps 3037.57 | loss 11.19 | ppl 72317.60
| batch    12 | wps 3037.18 | loss 11.06 | ppl 63817.07
| batch    13 | wps 3037.05 | loss 11.00 | ppl 60163.83
| batch    14 | wps 2916.40 | loss 10.91 | ppl 54649.08
| batch    15 | wps 3032.28 | loss 10.81 | ppl 49633.48
| batch    16 | wps 3028.42 | loss 10.73 | ppl 45730.61
| batch    17 | wps 3029.17 | loss 10.66 | ppl 42795.10
| batch    18 | wps 3031.76 | loss 10.55 | ppl 38331.11
| batch    19 | wps 3030.20 | loss 10.48 | ppl 35687.08
| batch    20 | wps 3031.20 | loss 10.43 | ppl 33985.76
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 71.60s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3024.60.
Elapsed_time(s) is 71.60.
Peak allocated bytes on cuda:0: 28.823833GB
Running FSDP benchmark with args: Namespace(batch_size=9, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 889.01 | loss 25.68 | ppl 141761382961.11
| batch     2 | wps 2961.41 | loss 12.52 | ppl 273540.01
| batch     3 | wps 3068.70 | loss 12.19 | ppl 196190.05
| batch     4 | wps 3068.74 | loss 12.05 | ppl 171085.08
| batch     5 | wps 3065.72 | loss 11.85 | ppl 140781.89
| batch     6 | wps 3068.74 | loss 11.72 | ppl 122865.95
| batch     7 | wps 3068.56 | loss 11.60 | ppl 108925.78
| batch     8 | wps 3068.70 | loss 11.50 | ppl 98401.18
| batch     9 | wps 3068.63 | loss 11.38 | ppl 87165.56
| batch    10 | wps 3065.60 | loss 11.26 | ppl 77899.81
| batch    11 | wps 3067.51 | loss 11.16 | ppl 70300.48
| batch    12 | wps 2960.03 | loss 11.09 | ppl 65641.77
| batch    13 | wps 3061.11 | loss 10.96 | ppl 57684.00
| batch    14 | wps 3060.09 | loss 10.88 | ppl 53251.74
| batch    15 | wps 3058.60 | loss 10.81 | ppl 49755.37
| batch    16 | wps 3057.16 | loss 10.71 | ppl 44628.81
| batch    17 | wps 3056.45 | loss 10.62 | ppl 40881.39
| batch    18 | wps 3056.60 | loss 10.52 | ppl 37122.71
| batch    19 | wps 3056.36 | loss 10.47 | ppl 35370.55
| batch    20 | wps 3057.99 | loss 10.41 | ppl 33226.60
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 78.17s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3051.07.
Elapsed_time(s) is 78.17.
Peak allocated bytes on cuda:0: 31.945026GB
Running FSDP benchmark with args: Namespace(batch_size=10, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 948.96 | loss 25.68 | ppl 141863761913.77
| batch     2 | wps 3088.81 | loss 12.44 | ppl 253950.05
| batch     3 | wps 3087.25 | loss 12.20 | ppl 198963.41
| batch     4 | wps 3086.42 | loss 12.01 | ppl 164334.90
| batch     5 | wps 3089.32 | loss 11.84 | ppl 138453.56
| batch     6 | wps 3087.48 | loss 11.71 | ppl 121501.24
| batch     7 | wps 3086.30 | loss 11.58 | ppl 107105.00
| batch     8 | wps 3084.48 | loss 11.46 | ppl 95037.66
| batch     9 | wps 3086.61 | loss 11.34 | ppl 83705.67
| batch    10 | wps 3085.98 | loss 11.24 | ppl 75882.43
| batch    11 | wps 2985.85 | loss 11.15 | ppl 69822.15
| batch    12 | wps 3088.52 | loss 11.03 | ppl 61484.29
| batch    13 | wps 3080.90 | loss 10.96 | ppl 57454.79
| batch    14 | wps 3077.13 | loss 10.86 | ppl 52173.08
| batch    15 | wps 3080.24 | loss 10.75 | ppl 46575.14
| batch    16 | wps 3082.47 | loss 10.67 | ppl 42841.53
| batch    17 | wps 3086.93 | loss 10.60 | ppl 39962.11
| batch    18 | wps 3082.99 | loss 10.53 | ppl 37239.97
| batch    19 | wps 3084.13 | loss 10.46 | ppl 34849.65
| batch    20 | wps 2988.09 | loss 10.37 | ppl 31738.56
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 84.92s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3073.80.
Elapsed_time(s) is 84.92.
Peak allocated bytes on cuda:0: 34.951633GB
Running FSDP benchmark with args: Namespace(batch_size=11, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 1017.64 | loss 25.65 | ppl 137576460891.74
| batch     2 | wps 3085.73 | loss 12.47 | ppl 260424.42
| batch     3 | wps 3084.50 | loss 12.23 | ppl 205344.20
| batch     4 | wps 3082.09 | loss 12.01 | ppl 164262.66
| batch     5 | wps 3084.50 | loss 11.85 | ppl 140468.88
| batch     6 | wps 3084.60 | loss 11.71 | ppl 121470.77
| batch     7 | wps 3084.21 | loss 11.59 | ppl 107706.67
| batch     8 | wps 3085.77 | loss 11.45 | ppl 94035.66
| batch     9 | wps 3085.91 | loss 11.33 | ppl 83342.84
| batch    10 | wps 2996.30 | loss 11.24 | ppl 76454.39
| batch    11 | wps 3085.06 | loss 11.14 | ppl 68753.03
| batch    12 | wps 3084.68 | loss 11.04 | ppl 62016.41
| batch    13 | wps 3080.76 | loss 10.95 | ppl 56868.71
| batch    14 | wps 3076.96 | loss 10.84 | ppl 50839.83
| batch    15 | wps 3078.29 | loss 10.73 | ppl 45847.29
| batch    16 | wps 3076.38 | loss 10.68 | ppl 43515.98
| batch    17 | wps 3082.56 | loss 10.61 | ppl 40580.27
| batch    18 | wps 2994.04 | loss 10.50 | ppl 36291.68
| batch    19 | wps 3080.17 | loss 10.42 | ppl 33467.63
| batch    20 | wps 3080.05 | loss 10.35 | ppl 31175.22
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 91.84s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3072.58.
Elapsed_time(s) is 91.84.
Peak allocated bytes on cuda:0: 38.073231GB
Running FSDP benchmark with args: Namespace(batch_size=12, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 1080.40 | loss 25.65 | ppl 137309852374.16
| batch     2 | wps 3112.61 | loss 12.44 | ppl 252622.24
| batch     3 | wps 3113.22 | loss 12.20 | ppl 199717.56
| batch     4 | wps 3113.64 | loss 11.97 | ppl 158373.07
| batch     5 | wps 3113.08 | loss 11.83 | ppl 136712.17
| batch     6 | wps 3111.34 | loss 11.70 | ppl 121023.28
| batch     7 | wps 3112.75 | loss 11.54 | ppl 103099.95
| batch     8 | wps 3112.13 | loss 11.42 | ppl 91379.04
| batch     9 | wps 3024.71 | loss 11.33 | ppl 83677.82
| batch    10 | wps 3108.40 | loss 11.22 | ppl 74520.90
| batch    11 | wps 3105.36 | loss 11.13 | ppl 67854.31
| batch    12 | wps 3106.82 | loss 11.01 | ppl 60721.34
| batch    13 | wps 3108.48 | loss 10.91 | ppl 54941.14
| batch    14 | wps 3108.14 | loss 10.80 | ppl 49252.58
| batch    15 | wps 3107.15 | loss 10.76 | ppl 46869.71
| batch    16 | wps 3110.24 | loss 10.66 | ppl 42566.91
| batch    17 | wps 3027.79 | loss 10.55 | ppl 38082.61
| batch    18 | wps 3108.89 | loss 10.47 | ppl 35354.80
| batch    19 | wps 3102.54 | loss 10.41 | ppl 33184.26
| batch    20 | wps 3104.36 | loss 10.34 | ppl 31035.29
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 98.12s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3099.72.
Elapsed_time(s) is 98.12.
Peak allocated bytes on cuda:0: 41.072514GB
Running FSDP benchmark with args: Namespace(batch_size=13, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 1134.34 | loss 25.67 | ppl 140511378194.26
| batch     2 | wps 3101.64 | loss 12.43 | ppl 249487.97
| batch     3 | wps 3103.52 | loss 12.17 | ppl 192526.44
| batch     4 | wps 3102.92 | loss 11.95 | ppl 154503.10
| batch     5 | wps 3103.55 | loss 11.80 | ppl 133024.47
| batch     6 | wps 3102.23 | loss 11.67 | ppl 116662.10
| batch     7 | wps 3103.66 | loss 11.51 | ppl 99908.74
| batch     8 | wps 3023.56 | loss 11.43 | ppl 91928.84
| batch     9 | wps 3096.00 | loss 11.29 | ppl 79685.12
| batch    10 | wps 3099.53 | loss 11.22 | ppl 74329.19
| batch    11 | wps 3092.82 | loss 11.10 | ppl 66390.46
| batch    12 | wps 3093.37 | loss 10.97 | ppl 58297.77
| batch    13 | wps 3094.23 | loss 10.88 | ppl 53249.71
| batch    14 | wps 3095.21 | loss 10.81 | ppl 49394.97
| batch    15 | wps 3021.73 | loss 10.72 | ppl 45066.17
| batch    16 | wps 3094.79 | loss 10.61 | ppl 40634.91
| batch    17 | wps 3095.16 | loss 10.52 | ppl 37178.15
| batch    18 | wps 3095.16 | loss 10.47 | ppl 35337.91
| batch    19 | wps 3098.62 | loss 10.38 | ppl 32263.50
| batch    20 | wps 3095.09 | loss 10.31 | ppl 30074.58
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 105.40s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3089.26.
Elapsed_time(s) is 105.40.
Peak allocated bytes on cuda:0: 44.197991GB
Running FSDP benchmark with args: Namespace(batch_size=14, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 1185.13 | loss 25.67 | ppl 141265279223.92
| batch     2 | wps 3125.79 | loss 12.44 | ppl 251831.82
| batch     3 | wps 3124.48 | loss 12.15 | ppl 189850.77
| batch     4 | wps 3121.20 | loss 11.96 | ppl 156675.22
| batch     5 | wps 3122.73 | loss 11.81 | ppl 135149.20
| batch     6 | wps 3117.62 | loss 11.65 | ppl 114376.85
| batch     7 | wps 3124.40 | loss 11.52 | ppl 100840.42
| batch     8 | wps 3054.79 | loss 11.42 | ppl 90966.38
| batch     9 | wps 3124.68 | loss 11.30 | ppl 80747.38
| batch    10 | wps 3120.99 | loss 11.21 | ppl 73660.08
| batch    11 | wps 3122.30 | loss 11.08 | ppl 64952.30
| batch    12 | wps 3116.71 | loss 10.96 | ppl 57702.66
| batch    13 | wps 3124.39 | loss 10.89 | ppl 53828.77
| batch    14 | wps 3051.45 | loss 10.80 | ppl 48939.91
| batch    15 | wps 3124.40 | loss 10.69 | ppl 43902.09
| batch    16 | wps 3120.44 | loss 10.61 | ppl 40412.62
| batch    17 | wps 3120.04 | loss 10.54 | ppl 37715.97
| batch    18 | wps 3120.78 | loss 10.45 | ppl 34693.53
| batch    19 | wps 3118.15 | loss 10.37 | ppl 31848.63
| batch    20 | wps 3120.65 | loss 10.30 | ppl 29881.15
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 111.83s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 3110.43.
Elapsed_time(s) is 111.83.
Peak allocated bytes on cuda:0: 47.196362GB
Running RTP-out-of-place benchmark with args: Namespace(batch_size=1, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 65.58 | loss 25.91 | ppl 179552328970.37
| batch     2 | wps 1290.92 | loss 12.77 | ppl 350290.01
| batch     3 | wps 1282.03 | loss 12.60 | ppl 295809.59
| batch     4 | wps 1275.01 | loss 12.49 | ppl 266387.23
| batch     5 | wps 1260.68 | loss 12.43 | ppl 250693.61
| batch     6 | wps 1251.62 | loss 12.24 | ppl 206405.20
| batch     7 | wps 1249.31 | loss 12.22 | ppl 202414.89
| batch     8 | wps 1084.91 | loss 12.31 | ppl 221841.01
| batch     9 | wps 1235.45 | loss 11.93 | ppl 152511.56
| batch    10 | wps 1226.18 | loss 11.94 | ppl 153879.76
| batch    11 | wps 1218.86 | loss 11.84 | ppl 138346.25
| batch    12 | wps 1214.98 | loss 11.83 | ppl 137604.78
| batch    13 | wps 1215.88 | loss 11.78 | ppl 130416.71
| batch    14 | wps 1211.88 | loss 11.72 | ppl 123016.84
| batch    15 | wps 1205.05 | loss 11.67 | ppl 116921.73
| batch    16 | wps 1046.91 | loss 11.46 | ppl 94965.18
| batch    17 | wps 1199.09 | loss 11.46 | ppl 94935.84
| batch    18 | wps 1197.68 | loss 11.35 | ppl 85043.47
| batch    19 | wps 1196.82 | loss 11.43 | ppl 92319.80
| batch    20 | wps 1185.24 | loss 11.26 | ppl 77871.29
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 47.66s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 1208.79.
Elapsed_time(s) is 47.66.
Peak allocated bytes on cuda:0: 4.534651GB
Running RTP-out-of-place benchmark with args: Namespace(batch_size=2, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 130.88 | loss 25.81 | ppl 161695064541.80
| batch     2 | wps 1884.53 | loss 12.59 | ppl 293161.25
| batch     3 | wps 1881.65 | loss 12.35 | ppl 230532.12
| batch     4 | wps 1882.93 | loss 12.21 | ppl 200299.90
| batch     5 | wps 1882.80 | loss 12.07 | ppl 173792.87
| batch     6 | wps 1882.05 | loss 12.02 | ppl 166082.48
| batch     7 | wps 1726.94 | loss 11.97 | ppl 158306.32
| batch     8 | wps 1883.90 | loss 11.77 | ppl 128959.65
| batch     9 | wps 1882.37 | loss 11.78 | ppl 131003.33
| batch    10 | wps 1884.10 | loss 11.63 | ppl 111873.49
| batch    11 | wps 1884.10 | loss 11.51 | ppl 99336.51
| batch    12 | wps 1882.01 | loss 11.53 | ppl 102023.07
| batch    13 | wps 1884.07 | loss 11.36 | ppl 86090.01
| batch    14 | wps 1728.45 | loss 11.32 | ppl 82768.04
| batch    15 | wps 1882.91 | loss 11.22 | ppl 74544.50
| batch    16 | wps 1883.69 | loss 11.14 | ppl 68899.47
| batch    17 | wps 1883.33 | loss 11.05 | ppl 62917.26
| batch    18 | wps 1882.68 | loss 11.04 | ppl 62069.01
| batch    19 | wps 1883.27 | loss 10.97 | ppl 58004.90
| batch    20 | wps 1884.35 | loss 10.92 | ppl 55397.35
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 52.49s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 1862.71.
Elapsed_time(s) is 52.49.
Peak allocated bytes on cuda:0: 7.866786GB
Running RTP-out-of-place benchmark with args: Namespace(batch_size=3, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 192.63 | loss 25.82 | ppl 163844337973.24
| batch     2 | wps 2228.53 | loss 12.54 | ppl 279417.80
| batch     3 | wps 2225.62 | loss 12.26 | ppl 211517.91
| batch     4 | wps 2228.25 | loss 12.15 | ppl 188318.37
| batch     5 | wps 2224.99 | loss 12.04 | ppl 169117.52
| batch     6 | wps 2166.76 | loss 11.95 | ppl 154426.06
| batch     7 | wps 2073.92 | loss 11.75 | ppl 127210.95
| batch     8 | wps 2226.20 | loss 11.74 | ppl 125702.40
| batch     9 | wps 2227.88 | loss 11.61 | ppl 109986.44
| batch    10 | wps 2225.74 | loss 11.49 | ppl 98043.35
| batch    11 | wps 2228.00 | loss 11.40 | ppl 89380.14
| batch    12 | wps 2225.63 | loss 11.41 | ppl 89805.73
| batch    13 | wps 2108.34 | loss 11.26 | ppl 77998.01
| batch    14 | wps 2228.38 | loss 11.18 | ppl 71466.21
| batch    15 | wps 2225.31 | loss 11.12 | ppl 67352.15
| batch    16 | wps 2228.37 | loss 11.00 | ppl 59709.23
| batch    17 | wps 2225.45 | loss 10.93 | ppl 55894.65
| batch    18 | wps 2227.06 | loss 10.82 | ppl 49962.88
| batch    19 | wps 2228.49 | loss 10.78 | ppl 47952.65
| batch    20 | wps 2098.04 | loss 10.73 | ppl 45802.19
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 58.75s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2200.78.
Elapsed_time(s) is 58.75.
Peak allocated bytes on cuda:0: 10.875562GB
Running RTP-out-of-place benchmark with args: Namespace(batch_size=4, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 246.99 | loss 25.75 | ppl 152752780748.36
| batch     2 | wps 2265.07 | loss 12.50 | ppl 267615.58
| batch     3 | wps 2268.45 | loss 12.26 | ppl 211458.00
| batch     4 | wps 2263.64 | loss 12.12 | ppl 182915.45
| batch     5 | wps 2266.91 | loss 11.91 | ppl 149244.98
| batch     6 | wps 2191.27 | loss 11.86 | ppl 141476.25
| batch     7 | wps 2267.69 | loss 11.73 | ppl 124689.81
| batch     8 | wps 2264.85 | loss 11.61 | ppl 110081.40
| batch     9 | wps 2264.98 | loss 11.55 | ppl 103899.16
| batch    10 | wps 2265.76 | loss 11.45 | ppl 93452.41
| batch    11 | wps 2266.16 | loss 11.36 | ppl 85722.08
| batch    12 | wps 2205.61 | loss 11.23 | ppl 75048.17
| batch    13 | wps 2265.23 | loss 11.12 | ppl 67378.04
| batch    14 | wps 2265.91 | loss 11.08 | ppl 64690.57
| batch    15 | wps 2266.00 | loss 11.00 | ppl 60079.08
| batch    16 | wps 2262.67 | loss 10.94 | ppl 56125.08
| batch    17 | wps 2266.82 | loss 10.82 | ppl 49901.30
| batch    18 | wps 2207.74 | loss 10.77 | ppl 47365.70
| batch    19 | wps 2265.61 | loss 10.69 | ppl 44040.14
| batch    20 | wps 2266.58 | loss 10.66 | ppl 42539.48
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 68.03s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2253.68.
Elapsed_time(s) is 68.03.
Peak allocated bytes on cuda:0: 13.919411GB
Running RTP-out-of-place benchmark with args: Namespace(batch_size=5, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 306.09 | loss 25.70 | ppl 145724364158.09
| batch     2 | wps 2395.26 | loss 12.44 | ppl 253237.33
| batch     3 | wps 2400.34 | loss 12.24 | ppl 206252.70
| batch     4 | wps 2399.67 | loss 12.03 | ppl 166906.56
| batch     5 | wps 2399.66 | loss 11.92 | ppl 150384.97
| batch     6 | wps 2271.34 | loss 11.76 | ppl 128077.31
| batch     7 | wps 2400.36 | loss 11.71 | ppl 121511.44
| batch     8 | wps 2397.29 | loss 11.58 | ppl 107196.66
| batch     9 | wps 2399.86 | loss 11.45 | ppl 94181.05
| batch    10 | wps 2400.30 | loss 11.36 | ppl 85774.75
| batch    11 | wps 2399.21 | loss 11.26 | ppl 77757.68
| batch    12 | wps 2266.89 | loss 11.20 | ppl 73110.76
| batch    13 | wps 2400.91 | loss 11.10 | ppl 66253.78
| batch    14 | wps 2398.01 | loss 11.00 | ppl 59987.54
| batch    15 | wps 2401.23 | loss 10.95 | ppl 56671.86
| batch    16 | wps 2399.89 | loss 10.87 | ppl 52348.21
| batch    17 | wps 2398.42 | loss 10.75 | ppl 46447.39
| batch    18 | wps 2262.47 | loss 10.68 | ppl 43446.31
| batch    19 | wps 2400.75 | loss 10.57 | ppl 39009.92
| batch    20 | wps 2400.40 | loss 10.51 | ppl 36601.86
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 74.71s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2376.95.
Elapsed_time(s) is 74.71.
Peak allocated bytes on cuda:0: 17.184782GB
Running RTP-out-of-place benchmark with args: Namespace(batch_size=6, benchmark_eval=False, checkpoint=False, clip_value=0.05, debug=False, dropout=0, dry_run=False, enable_auto_wrap=False, epochs=1, full_fp16=False, initrange=0.1, lr=0.0001, max_batch=20, model_config='gpt-xlc', model_name='lm', nhead=32, nhid=5120, ninp=1280, num_decoder_layers=36, seq_len=1025, use_synthetic_data=True, vocab_size=50256)
--------------------------------------------------------------------------------------------------------------
| start of epoch 1
--------------------------------------------------------------------------------------------------------------
| batch     1 | wps 359.16 | loss 25.71 | ppl 145884967082.21
| batch     2 | wps 2461.88 | loss 12.42 | ppl 248447.06
| batch     3 | wps 2458.76 | loss 12.20 | ppl 199298.98
| batch     4 | wps 2458.69 | loss 12.05 | ppl 171015.59
| batch     5 | wps 2457.99 | loss 11.88 | ppl 144501.11
| batch     6 | wps 2458.89 | loss 11.78 | ppl 130757.20
| batch     7 | wps 2459.09 | loss 11.66 | ppl 115492.24
| batch     8 | wps 2458.44 | loss 11.51 | ppl 99389.39
| batch     9 | wps 2457.85 | loss 11.40 | ppl 89012.67
| batch    10 | wps 2457.55 | loss 11.33 | ppl 83341.33
| batch    11 | wps 2458.61 | loss 11.24 | ppl 75984.60
| batch    12 | wps 2461.18 | loss 11.16 | ppl 70342.93
| batch    13 | wps 2459.77 | loss 11.07 | ppl 64518.98
| batch    14 | wps 2457.96 | loss 10.94 | ppl 56586.64
| batch    15 | wps 2460.04 | loss 10.87 | ppl 52498.80
| batch    16 | wps 2457.84 | loss 10.74 | ppl 45939.55
| batch    17 | wps 2458.02 | loss 10.73 | ppl 45770.40
| batch    18 | wps 2365.68 | loss 10.62 | ppl 41082.74
| batch    19 | wps 2457.57 | loss 10.56 | ppl 38383.97
| batch    20 | wps 2460.05 | loss 10.47 | ppl 35095.69
--------------------------------------------------------------------------------------------------------------
| end of epoch 1 | time: 82.13s 
--------------------------------------------------------------------------------------------------------------
Throughput(wps) is 2452.89.
Elapsed_time(s) is 82.13.
Peak allocated bytes on cuda:0: 20.123580GB
